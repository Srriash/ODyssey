import json
import io
import os
import re
import zipfile
from datetime import datetime, timezone
import numpy as np
import pandas as pd
import streamlit as st
import plotly.colors as pc
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
APP_TITLE = "ODyssey Growth Curve Workbench"
CONFIG_VERSION = 1
from odyssey.analysis import (
    _base_time_unit,
    _build_column_map,
    _compute_auc,
    _convert_auc,
    _convert_duration,
    _convert_growth_rate,
    _long_format_from_map,
    _mean_sd_by_treatment_time,
    _qc_flags,
    _suggest_treatment_name,
    _validate_data,
    _window_r2_by_treatment,
    fit_growth_rates,
)
from odyssey.export import _build_config, _build_report_pdf
from odyssey.cache import _cached_preview_data
from odyssey.io_utils import (
    _apply_time_unit,
    _guess_time_columns,
    _parse_time_series,
    _read_excel_file,
    _read_results_zip,
    _safe_filename,
    _safe_read_json,
)
from odyssey.plotting import (
    _add_window_highlight,
    _add_window_highlight_color,
    _apply_tick_intervals,
    _plot_compare_runs,
    _plot_overlay,
    _plot_small_multiples,
    _plot_to_png_bytes,
    _prepare_download_figure,
    _style_plot,
    _to_rgba,
)
def _analyze_file(
    uploaded,
    sheet_name,
    time_col,
    time_unit,
    column_map,
    time_window,
    auto_window,
    min_points,
    blank_normalized,
    blank_cols,
    auc_window=None,
):
    df = _read_excel_file(uploaded, sheet_name)
    if not blank_normalized and blank_cols:
        df = _apply_blank_normalization(df, time_col, blank_cols)
    time_series = _parse_time_series(df[time_col])
    time_series = _apply_time_unit(time_series, time_unit if time_unit != "hh:mm:ss" else "minutes")
    working_df = df.copy()
    working_df["_time_numeric"] = time_series
    if time_series.isna().all():
        raise ValueError(f"Time column could not be parsed in {uploaded.name}.")
    column_map_df = pd.DataFrame(column_map)
    long_df = _long_format_from_map(working_df, "_time_numeric", column_map_df)
    if long_df.empty:
        raise ValueError(f"No treatment columns selected in {uploaded.name}.")
    results = fit_growth_rates(
        long_df,
        time_col="time",
        value_col="od",
        group_cols=("treatment", "replicate"),
        time_window=time_window,
        auto_window=auto_window,
        min_points=min_points,
    )
    mean_df = _mean_sd_by_treatment_time(long_df)
    auc_df = _compute_auc(
        long_df,
        time_col="time",
        value_col="od",
        group_cols=("treatment", "replicate"),
        time_window=auc_window,
    )
    return {
        "name": uploaded.name,
        "long_df": long_df,
        "results": results,
        "mean_df": mean_df,
        "auc": auc_df,
    }
def _apply_blank_normalization(df, time_col, blank_col):
    working_df = df.copy()
    data_cols = [c for c in working_df.columns if c != time_col]
    numeric = working_df[data_cols].apply(pd.to_numeric, errors="coerce")
    if isinstance(blank_col, (list, tuple, pd.Index)):
        blank_cols = list(blank_col)
    else:
        blank_cols = [blank_col]
    blank_vals = working_df[blank_cols].apply(pd.to_numeric, errors="coerce")
    blank_mean = blank_vals.mean(axis=1)
    working_df[data_cols] = numeric.sub(blank_mean, axis=0)
    return working_df
def main():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.markdown(
        """
        <style>
        /* Customize Streamlit's drag-drop text inside the upload box */
        div[data-testid="stFileUploaderDropzone"] p {
          visibility: hidden;
          margin: 0;
          height: 0;
        }
        div[data-testid="stFileUploaderDropzone"] p::before {
          content: "Upload file - drag and drop files here";
          visibility: visible;
          display: block;
          height: auto;
          margin-bottom: 4px;
          font-weight: 600;
        }
        div[data-testid="stFileUploaderDropzone"] small {
          display: block;
          margin-top: 0;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        "Learn more: [ODyssey home](https://srriash.github.io/ODyssey-Growth-curve-workbench/)  \n"
        "Upload an Excel file or compare runs from zip exports. A JSON config is optional."
    )
    st.subheader("Compare runs")
    st.caption("Compare previously analyzed runs by uploading ODyssey zip exports.")
    st.info("Comparison does not require re-running analysis.")
    compare_upload = st.file_uploader(
        "Upload ODyssey zip(s)",
        type=["zip"],
        accept_multiple_files=True,
        help="Use the zip files generated by the Downloads section.",
    )
    if compare_upload:
        compare_runs = []
        compare_errors = []
        for uploaded in compare_upload:
            parsed, err = _read_results_zip(uploaded)
            if err:
                compare_errors.append(err)
            else:
                compare_runs.append(parsed)
        if compare_errors:
            st.warning("Some zip files could not be parsed:")
            for err in compare_errors:
                st.write(f"- {err}")
        if compare_runs:
            st.success(f"Loaded {len(compare_runs)} run(s) for comparison.")
            st.warning(
                "Comparison assumes consistent units and treatment naming across runs. "
                "If runs used different time units or window settings, interpret differences carefully."
            )
            combined_frames = []
            compare_warnings = []
            required_cols = {"treatment", "replicate"}
            for run in compare_runs:
                results_df = run["results"].copy()
                missing = required_cols - set(results_df.columns)
                if missing:
                    compare_warnings.append(
                        f"{run['name']}: missing columns {', '.join(sorted(missing))}"
                    )
                    continue
                results_df["run"] = run["name"]
                combined_frames.append(results_df)
            if compare_warnings:
                st.warning("Some runs were skipped:")
                for msg in compare_warnings:
                    st.write(f"- {msg}")
            if combined_frames:
                combined_compare = pd.concat(combined_frames, ignore_index=True)
                treatments = sorted(combined_compare["treatment"].dropna().unique().tolist())
                rename_map = {}
                with st.expander("Rename treatments (optional)", expanded=False):
                    st.caption("Provide display names used in comparison tables and plots.")
                    for treatment in treatments:
                        rename_map[treatment] = st.text_input(
                            f"Rename {treatment}",
                            value=str(treatment),
                            key=f"rename_{treatment}",
                        )
                combined_compare["treatment_display"] = combined_compare["treatment"].map(rename_map)
                combined_compare = combined_compare.sort_values(["treatment_display", "run"])
                st.markdown("### Comparison table")
                st.dataframe(combined_compare)
                st.markdown("### Summary by treatment")
                numeric_cols = combined_compare.select_dtypes(include="number").columns.tolist()
                numeric_cols = [c for c in numeric_cols if c not in ("replicate",)]
                if numeric_cols:
                    summary = (
                        combined_compare.groupby(["run", "treatment_display"])[numeric_cols]
                        .mean()
                        .reset_index()
                    )
                    summary = summary.sort_values(["treatment_display", "run"])
                    st.dataframe(summary)
                    metric_options = [c for c in numeric_cols if c not in ("n", "window_start", "window_end")]
                    if metric_options:
                        st.markdown("### Compare a metric across runs")
                        metric = st.selectbox("Metric", options=metric_options)
                        treatments = summary["treatment_display"].dropna().unique().tolist()
                        selected_treatments = st.multiselect(
                            "Treatments to compare",
                            options=sorted(treatments),
                            default=sorted(treatments)[:3],
                        )
                        if selected_treatments:
                            plot_df = summary[summary["treatment_display"].isin(selected_treatments)]
                            fig = go.Figure()
                            for treatment in selected_treatments:
                                subset = plot_df[plot_df["treatment_display"] == treatment]
                                fig.add_trace(
                                    go.Bar(
                                        x=subset["run"],
                                        y=subset[metric],
                                        name=str(treatment),
                                    )
                                )
                            fig.update_layout(barmode="group")
                            _style_plot(fig, f"{metric} by run", "Run", metric, show_grid=False)
                            st.plotly_chart(fig, width="stretch", key="compare_metric_plot")
                else:
                    st.info("No numeric columns available for summary.")
            curve_runs = [run for run in compare_runs if run.get("long_df") is not None]
            if curve_runs:
                st.markdown("### Compare growth curves")
                st.caption("Uses long_df.csv from each zip. Enable in Downloads when exporting.")
                show_sd_compare = st.checkbox("Show SD band", value=True, key="compare_show_sd")
                custom_ticks_compare = st.checkbox(
                    "Custom tick intervals",
                    value=False,
                    key="compare_custom_ticks",
                )
                x_tick_interval_compare = None
                y_tick_interval_compare = None
                if custom_ticks_compare:
                    x_tick_interval_compare = st.number_input(
                        "X-axis tick interval",
                        min_value=0.001,
                        value=5.0,
                        key="compare_x_tick_interval",
                    )
                    y_tick_interval_compare = st.number_input(
                        "Y-axis tick interval",
                        min_value=0.001,
                        value=0.1,
                        key="compare_y_tick_interval",
                    )
                run_labels = [run["name"] for run in curve_runs]
                selected_runs = st.multiselect(
                    "Runs to compare",
                    options=run_labels,
                    default=run_labels,
                    key="compare_runs_select",
                )
                all_treatments = sorted(
                    {
                        t
                        for run in curve_runs
                        for t in run["long_df"]["treatment"].dropna().unique().tolist()
                    }
                )
                selected_treatments = st.multiselect(
                    "Treatments to plot",
                    options=all_treatments,
                    default=all_treatments[:3],
                    key="compare_treatments_select",
                )
                if selected_runs and selected_treatments:
                    curves = []
                    for run in curve_runs:
                        if run["name"] not in selected_runs:
                            continue
                        df = run["long_df"].copy()
                        df["run"] = run["name"]
                        curves.append(df)
                    curves_df = pd.concat(curves, ignore_index=True)
                    curves_df = curves_df[curves_df["treatment"].isin(selected_treatments)]
                    grouped = (
                        curves_df.groupby(["run", "treatment", "time"])["od"]
                        .agg(mean="mean", sd=lambda x: x.std(ddof=1))
                        .reset_index()
                        .sort_values(["treatment", "run", "time"])
                    )
                    fig = go.Figure()
                    color_cycle = pc.qualitative.Plotly
                    run_styles = {}
                    for idx, run in enumerate(selected_runs):
                        run_styles[run] = dict(dash="solid" if idx % 2 == 0 else "dot")
                    for idx, treatment in enumerate(selected_treatments):
                        color = color_cycle[idx % len(color_cycle)]
                        subset = grouped[grouped["treatment"] == treatment]
                        for run in selected_runs:
                            run_subset = subset[subset["run"] == run]
                            if run_subset.empty:
                                continue
                            line_name = f"{rename_map.get(treatment, treatment)} - {run}"
                            if show_sd_compare and not run_subset["sd"].isna().all():
                                upper = run_subset["mean"] + run_subset["sd"]
                                lower = run_subset["mean"] - run_subset["sd"]
                                fig.add_trace(
                                    go.Scatter(
                                        x=run_subset["time"],
                                        y=lower,
                                        mode="lines",
                                        line=dict(width=0),
                                        showlegend=False,
                                        hoverinfo="skip",
                                    )
                                )
                                fig.add_trace(
                                    go.Scatter(
                                        x=run_subset["time"],
                                        y=upper,
                                        mode="lines",
                                        line=dict(width=0),
                                        fill="tonexty",
                                        fillcolor=_to_rgba(color, 0.12),
                                        showlegend=False,
                                        hoverinfo="skip",
                                    )
                                )
                            fig.add_trace(
                                go.Scatter(
                                    x=run_subset["time"],
                                    y=run_subset["mean"],
                                    mode="lines",
                                    name=line_name,
                                    line=dict(color=color, **run_styles[run]),
                                )
                            )
                    _style_plot(fig, "Growth curves across runs", "Time", "OD", show_grid=False)
                    _apply_tick_intervals(fig, x_tick_interval_compare, y_tick_interval_compare)
                    st.plotly_chart(fig, width="stretch", key="compare_growth_curves")
                    html = pio.to_html(fig, full_html=False, include_plotlyjs="cdn")
                    st.download_button(
                        "Download comparison plot (HTML)",
                        data=html,
                        file_name="odyssey_compare_growth_curves.html",
                        mime="text/html",
                        key="download_compare_growth_curves",
                    )
    st.divider()
    st.subheader("Run analysis")
    st.caption("Analyze a single Excel file and generate plots, reports, and exports.")
    excel_upload = st.file_uploader("Upload Excel file", type=["xlsx", "xls"], accept_multiple_files=False)
    if not excel_upload:
        st.info("Upload an Excel file to continue analysis.")
        return
    st.caption(
        "Optional config: upload a saved config to restore your sheet, columns, plots, and labels."
    )
    config_upload = st.file_uploader("Upload config (optional)", type=["json"])
    config = _safe_read_json(config_upload) if config_upload else None
    try:
        xls = pd.ExcelFile(excel_upload)
    except Exception as exc:
        st.error(f"Could not read Excel file: {exc}")
        return
    sheet_names = xls.sheet_names
    default_sheet = config.get("sheet_name") if config else sheet_names[0]
    if default_sheet not in sheet_names:
        default_sheet = sheet_names[0]
    sheet_name = st.selectbox("Sheet", options=sheet_names, index=sheet_names.index(default_sheet))
    try:
        df = pd.read_excel(xls, sheet_name=sheet_name, mangle_dupe_cols=False)
    except TypeError:
        df = pd.read_excel(xls, sheet_name=sheet_name)
    if df.empty:
        st.warning("The selected sheet is empty.")
        return
    time_candidates = _guess_time_columns(df)
    default_time = config.get("time_col") if config else time_candidates[0]
    if default_time not in df.columns:
        default_time = time_candidates[0]
    st.subheader("Preview")
    col1, col2 = st.columns([2, 3])
    with col1:
        time_col = st.selectbox("Time column", options=df.columns.tolist(), index=df.columns.get_loc(default_time))
        time_unit = st.selectbox("Time unit", options=["minutes", "hours", "hh:mm:ss"], index=0)
        blank_normalized_default = config.get("blank_normalized", False) if config else False
        blank_normalized = st.checkbox(
            "OD values are blank normalized",
            value=blank_normalized_default,
        )
        blank_candidates = [c for c in df.columns if c != time_col]
        blank_cols = []
        working_df = df.copy()
        if blank_candidates:
            default_blank_cols = []
            if config:
                default_blank_cols = config.get("blank_cols") or []
                if not default_blank_cols and config.get("blank_col"):
                    default_blank_cols = [config.get("blank_col")]
            default_blank_cols = [c for c in default_blank_cols if c in blank_candidates]
            blank_cols = st.multiselect(
                "Blank column(s)",
                options=blank_candidates,
                default=default_blank_cols,
            )
            if not blank_normalized and blank_cols:
                working_df = _apply_blank_normalization(df, time_col, blank_cols)
            elif not blank_normalized and not blank_cols:
                st.warning("Select at least one blank column for normalization.")
        else:
            if not blank_normalized:
                st.warning("No columns available for blank normalization.")
            blank_normalized = True
        base_unit = _base_time_unit(time_unit)
        fit_window_mode = "Auto+Manual"
        min_points = int(config.get("min_points", 5)) if config else 5
        time_window = None
    preview_df = working_df.copy()
    for col in preview_df.columns:
        if preview_df[col].dtype == object:
            sample = preview_df[col].dropna().head(5)
            if any(isinstance(v, (datetime, pd.Timestamp)) for v in sample):
                preview_df[col] = preview_df[col].astype(str)
    st.dataframe(preview_df.head(10))
    validation_issues = _validate_data(
        working_df,
        time_col=time_col,
        data_cols=[c for c in working_df.columns if c != time_col],
    )
    if validation_issues:
        st.warning("Data validation warnings:")
        for issue in validation_issues[:10]:
            st.write(f"- {issue}")
    with col2:
        config_map = config.get("column_map") if config else None
        available_cols = [
            c
            for c in working_df.columns
            if c != time_col and c not in set(blank_cols)
        ]
        if "replicate_groups" not in st.session_state:
            st.session_state.replicate_groups = []
        if "plot_groups" not in st.session_state:
            st.session_state.plot_groups = []
        if "plot_mode" not in st.session_state:
            st.session_state.plot_mode = config.get("plot_mode") if config else "Overlay (compare treatments)"
        if "show_sd" not in st.session_state:
            st.session_state.show_sd = bool(config.get("show_sd")) if config else True
        if "plots_per_row" not in st.session_state:
            st.session_state.plots_per_row = (
                int(config.get("charts_per_row"))
                if config and config.get("charts_per_row")
                else 2
            )
        if "plot_title" not in st.session_state:
            st.session_state.plot_title = (
                config.get("plot_labels", {}).get("title")
                if config and config.get("plot_labels")
                else "Growth curves (mean across replicates)"
            )
        if "plot_x_label" not in st.session_state:
            st.session_state.plot_x_label = (
                config.get("plot_labels", {}).get("x_label")
                if config and config.get("plot_labels")
                else "Time"
            )
        if "plot_y_label" not in st.session_state:
            st.session_state.plot_y_label = (
                config.get("plot_labels", {}).get("y_label")
                if config and config.get("plot_labels")
                else "OD"
            )
        if "analysis_ready" not in st.session_state:
            st.session_state.analysis_ready = False
        if "analysis_payload" not in st.session_state:
            st.session_state.analysis_payload = {}
        st.markdown("Select columns that are replicates, assign a treatment name, and add the group.")
        if "rep_cols" not in st.session_state:
            st.session_state.rep_cols = []
        if "rep_name" not in st.session_state:
            st.session_state.rep_name = ""
        def _update_group_name():
            st.session_state.rep_name = _suggest_treatment_name(st.session_state.rep_cols)
        used_cols = set()
        for group in st.session_state.replicate_groups:
            used_cols.update(group.get("columns", []))
        available_group_cols = [c for c in available_cols if c not in used_cols]
        group_cols = st.multiselect(
            "Replicate columns",
            options=available_group_cols,
            key="rep_cols",
            on_change=_update_group_name,
        )
        group_name = st.text_input("Treatment name for selected replicates", key="rep_name")
        def _add_group():
            if st.session_state.rep_cols and st.session_state.rep_name:
                st.session_state.replicate_groups.append(
                    {
                        "treatment": st.session_state.rep_name,
                        "columns": list(st.session_state.rep_cols),
                    }
                )
                st.session_state.rep_cols = []
                st.session_state.rep_name = ""
        st.button("Add replicate group", on_click=_add_group)
        if st.session_state.replicate_groups:
            st.write("Replicate groups")
            st.dataframe(pd.DataFrame(st.session_state.replicate_groups))
            if st.button("Clear replicate groups"):
                st.session_state.replicate_groups = []
        if config_map and not st.session_state.replicate_groups:
            st.session_state.replicate_groups = [
                {"treatment": row.get("treatment"), "columns": [row.get("column")]}
                for row in config_map
                if row.get("column") in available_cols
            ]
        if config and config.get("plot_groups") and not st.session_state.plot_groups:
            st.session_state.plot_groups = config.get("plot_groups")
        notes = st.text_area("Notes (saved into config)", value=(config.get("notes", "") if config else ""))
    if blank_cols:
        st.subheader("Blank control")
        st.caption("Check for contamination by reviewing blank OD over time.")
        try:
            blank_time = _parse_time_series(df[time_col])
            blank_time = _apply_time_unit(
                blank_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
            )
            fig = go.Figure()
            for col in blank_cols:
                fig.add_trace(
                    go.Scatter(
                        x=blank_time,
                        y=pd.to_numeric(df[col], errors="coerce"),
                        mode="lines",
                        name=str(col),
                    )
                )
            _style_plot(fig, "Blank OD over time", st.session_state.plot_x_label, "OD", show_grid=False)
            if available_cols:
                y_vals = working_df[available_cols].apply(pd.to_numeric, errors="coerce")
                y_min = float(np.nanmin(y_vals.to_numpy())) if not y_vals.empty else None
                y_max = float(np.nanmax(y_vals.to_numpy())) if not y_vals.empty else None
                if y_min is not None and y_max is not None and np.isfinite(y_min) and np.isfinite(y_max):
                    fig.update_yaxes(range=[y_min, y_max])
            st.plotly_chart(fig, width="stretch", key="blank_control_plot")
        except Exception as exc:
            st.warning(f"Blank control preview unavailable: {exc}")
    st.subheader("Analysis settings")
    st.markdown("### Growth rate")
    default_growth_unit = (config.get("growth_rate_unit") if config else None) or (
        "1/min" if base_unit == "minutes" else "1/hour"
    )
    growth_rate_unit_options = {"min\u207B\u00B9": "1/min", "h\u207B\u00B9": "1/hour"}
    default_growth_label = "min\u207B\u00B9" if default_growth_unit == "1/min" else "h\u207B\u00B9"
    growth_rate_label = st.selectbox(
        "Growth rate unit",
        options=list(growth_rate_unit_options.keys()),
        index=0 if default_growth_label == "min\u207B\u00B9" else 1,
    )
    growth_rate_unit = growth_rate_unit_options[growth_rate_label]
    st.markdown("### Doubling time")
    default_dt_unit = (config.get("doubling_time_unit") if config else None) or (
        "min" if base_unit == "minutes" else "hour"
    )
    doubling_time_unit = st.selectbox(
        "Doubling time unit",
        options=["min", "hour"],
        index=0 if default_dt_unit == "min" else 1,
    )
    st.subheader("Preview curves")
    time_window = None
    t_min = 0.0
    t_max = 1.0
    column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
    try:
        with st.spinner("Preparing preview..."):
            column_map_json = pd.DataFrame(column_map).to_json()
            preview_mean_df, preview_long_df, t_min, t_max = _cached_preview_data(
                excel_upload.getvalue(),
                sheet_name,
                time_col,
                time_unit,
                column_map_json,
                blank_normalized,
                blank_cols,
            )
            if preview_mean_df.empty:
                st.warning("Preview unavailable: no data after parsing.")
            else:
                preview_treatments = sorted(preview_mean_df["treatment"].dropna().unique().tolist())
                signature = (sheet_name, time_col, time_unit, column_map_json)
                if st.session_state.get("preview_signature") != signature:
                    st.session_state.preview_signature = signature
                    st.session_state.preview_base_fig = _plot_overlay(
                        preview_mean_df, preview_treatments, show_sd=True
                    )
                auto_window_range = (t_min, t_max)
                try:
                    mean_by_time = (
                        preview_mean_df.groupby("time")["mean"]
                        .mean()
                        .reset_index()
                        .sort_values("time")
                    )
                    time_vals = mean_by_time["time"].to_numpy(dtype=float)
                    od_vals = mean_by_time["mean"].to_numpy(dtype=float)
                    valid = np.isfinite(time_vals) & np.isfinite(od_vals) & (od_vals > 0)
                    time_vals = time_vals[valid]
                    od_vals = od_vals[valid]
                    if len(time_vals) > 3:
                        log_od = np.log(od_vals)
                        slopes = np.diff(log_od) / np.diff(time_vals)
                        if np.isfinite(slopes).any():
                            max_slope = np.nanmax(slopes)
                            thresh = 0.8 * max_slope
                            start_idx = 0
                            for idx, val in enumerate(slopes):
                                if val >= thresh:
                                    start_idx = idx
                                    break
                            start_time = float(time_vals[start_idx])
                            span = float(t_max - t_min)
                            end_time = min(t_max, start_time + 0.2 * span)
                            auto_window_range = (start_time, end_time)
                except Exception:
                    auto_window_range = (t_min, t_max)
                st.caption("Adjust the fit window as needed.")
                time_window = st.slider(
                    "Fit window range",
                    min_value=t_min,
                    max_value=t_max,
                    value=auto_window_range,
                    key="fit_window_range",
                )
                preview_fig = go.Figure(st.session_state.preview_base_fig)
                preview_fig = _add_window_highlight(preview_fig, time_window)
                _style_plot(
                    preview_fig,
                    st.session_state.plot_title,
                    st.session_state.plot_x_label,
                    st.session_state.plot_y_label,
                    show_grid=False,
                )
                st.plotly_chart(preview_fig, width="stretch", key="preview_plot")
                st.caption(f"Highlighted window: {time_window[0]:.2f} to {time_window[1]:.2f}.")
                live_r2 = st.checkbox("Calculate R\u00B2 live (can be slow)", value=False)
                if live_r2:
                    r2_df = _window_r2_by_treatment(preview_long_df, time_window=time_window)
                    if not r2_df.empty:
                        r2_median = r2_df["r2"].median()
                        st.caption(f"Median R\u00B2 in highlighted window: {r2_median:.3f}")
                else:
                    if st.button("Calculate R\u00B2 for highlighted window"):
                        r2_df = _window_r2_by_treatment(preview_long_df, time_window=time_window)
                        if not r2_df.empty:
                            r2_median = r2_df["r2"].median()
                            st.session_state.preview_r2_median = r2_median
                    if "preview_r2_median" in st.session_state:
                        st.caption(
                            f"Median R\u00B2 in highlighted window: {st.session_state.preview_r2_median:.3f}"
                        )
    except Exception as exc:
        st.warning(f"Preview unavailable: {exc}")
    st.markdown("### AUC")
    config_auc_unit = config.get("auc_unit") if config else None
    if config_auc_unit == "OD*min":
        config_auc_unit = "OD*min"
    if config_auc_unit == "OD*hour":
        config_auc_unit = "OD*hour"
    default_auc_unit = config_auc_unit or (
        "OD*min" if base_unit == "minutes" else "OD*hour"
    )
    auc_unit = st.selectbox(
        "AUC unit",
        options=["OD*min", "OD*hour"],
        index=0 if default_auc_unit == "OD*min" else 1,
    )
    auc_mode = st.selectbox(
        "AUC window",
        options=["Full range", "Fit window", "Custom range"],
        index=0
        if (config.get("auc_mode") if config else "Full range") == "Full range"
        else 1
        if (config.get("auc_mode") if config else "") == "Fit window"
        else 2,
    )
    auc_window = None
    auc_highlight = None
    auc_fig = None
    if "preview_base_fig" in st.session_state:
        auc_fig = go.Figure(st.session_state.preview_base_fig)
    if auc_mode == "Custom range":
        try:
            auc_time = _parse_time_series(df[time_col])
            auc_time = _apply_time_unit(
                auc_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
            )
            auc_time = auc_time.dropna()
            if not auc_time.empty:
                auc_min = float(auc_time.min())
                auc_max = float(auc_time.max())
            else:
                auc_min, auc_max = 0.0, 1.0
        except Exception:
            auc_min, auc_max = 0.0, 1.0
        default_auc = config.get("auc_window") if config else None
        auc_default = (
            tuple(default_auc) if isinstance(default_auc, list) and len(default_auc) == 2 else (auc_min, auc_max)
        )
        auc_window = st.slider(
            "AUC range",
            min_value=auc_min,
            max_value=auc_max,
            value=auc_default,
            key="auc_window",
        )
        auc_highlight = auc_window
        if auc_fig is not None:
            auc_fig = _add_window_highlight_color(auc_fig, auc_window, "rgba(239,68,68,0.25)")
    else:
        if auc_mode == "Fit window":
            auc_highlight = time_window
        else:
            auc_highlight = (t_min, t_max)
        if auc_fig is not None:
            auc_fig = _add_window_highlight_color(auc_fig, auc_highlight, "rgba(255,193,7,0.2)")
    if auc_fig is not None and auc_highlight is not None:
        _style_plot(
            auc_fig,
            "AUC window preview",
            st.session_state.plot_x_label,
            st.session_state.plot_y_label,
            show_grid=False,
        )
        st.plotly_chart(auc_fig, width="stretch", key="auc_preview_plot")
    col_a, _ = st.columns([1, 1])
    with col_a:
        run_button = st.button("Run analysis", type="primary")
    if run_button:
        if not available_cols:
            st.error("No treatment columns selected.")
            return
        column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
        base_unit = _base_time_unit(time_unit)
        target_mu_unit = "minutes" if growth_rate_unit == "1/min" else "hours"
        target_dt_unit = "minutes" if doubling_time_unit == "min" else "hours"
        with st.spinner("Running analysis..."):
            analyses = []
            errors = []
            uploaded = excel_upload
            try:
                if auc_mode == "Full range":
                    auc_use_window = None
                elif auc_mode == "Fit window":
                    auc_use_window = time_window
                else:
                    auc_use_window = auc_window
                if auc_use_window is None:
                    auc_time = _parse_time_series(df[time_col])
                    auc_time = _apply_time_unit(
                        auc_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
                    )
                    auc_time = auc_time.dropna()
                    if not auc_time.empty:
                        auc_window_range = (float(auc_time.min()), float(auc_time.max()))
                    else:
                        auc_window_range = (np.nan, np.nan)
                else:
                    auc_window_range = (float(auc_use_window[0]), float(auc_use_window[1]))
                analysis = _analyze_file(
                    uploaded,
                    sheet_name,
                    time_col,
                    time_unit,
                    column_map,
                    time_window,
                    False,
                    min_points,
                    blank_normalized,
                    blank_cols,
                    auc_window=auc_use_window,
                )
                analysis["results"]["run"] = uploaded.name
                analyses.append(analysis)
            except Exception as exc:
                errors.append(str(exc))
            if errors:
                st.error("Some files could not be processed:")
                for err in errors:
                    st.write(f"- {err}")
                if not analyses:
                    return
            combined_results = pd.concat([a["results"] for a in analyses], ignore_index=True)
            combined_auc = pd.concat([a["auc"] for a in analyses], ignore_index=True)
            combined_results = combined_results.merge(
                combined_auc, on=["treatment", "replicate"], how="left"
            )
            results_display = combined_results.copy()
            results_display["mu"] = _convert_growth_rate(results_display["mu"], base_unit, target_mu_unit)
            results_display["doubling_time"] = _convert_duration(
                results_display["doubling_time"], base_unit, target_dt_unit
            )
            target_auc_unit = "minutes" if auc_unit == "OD*min" else "hours"
            results_display["auc"] = _convert_auc(results_display["auc"], base_unit, target_auc_unit)
            mu_label = f"Growth rate ({growth_rate_label})"
            dt_label = f"Doubling time ({doubling_time_unit})"
            auc_label = f"AUC ({auc_unit})"
            results_display = results_display.rename(
                columns={"mu": mu_label, "doubling_time": dt_label, "auc": auc_label}
            )
            results_display["AUC window start"] = auc_window_range[0]
            results_display["AUC window end"] = auc_window_range[1]
            results_display = _qc_flags(results_display, r2_threshold=0.9)
            if "run" in results_display.columns:
                results_display = results_display.drop(columns=["run"])
            results_display = results_display.rename(
                columns={
                    "treatment": "Treatment",
                    "replicate": "Replicate",
                    "n": "N",
                    "intercept": "Intercept",
                    "r2": "R\u00B2",
                    "window_start": "Exponential window start",
                    "window_end": "Exponential window end",
                    "qc_flags": "QC flags",
                }
            )
            st.session_state.analysis_ready = True
            st.session_state.analysis_payload = {
                "analyses": analyses,
                "results": results_display,
            }
    if not st.session_state.analysis_ready:
        st.info("Run analysis to generate results and plots.")
        return
    analyses = st.session_state.analysis_payload["analyses"]
    results = st.session_state.analysis_payload["results"]
    st.subheader("Fit results")
    st.dataframe(results)
    st.markdown(
        "Fit definitions: "
        "**N** = number of points in the fit window; "
        "**Growth rate** = growth rate from the selected fit window (slope of ln(OD) vs time); "
        "**R<sup>2</sup>** = coefficient of determination for the linear fit; "
        "**Doubling time** = time for OD to double; "
        "**AUC** = area under the curve; "
        "**Exponential window start/end** = time range used for the fit; "
        "**QC flags** = low R<sup>2</sup> or non-positive growth rate.",
        unsafe_allow_html=True,
    )
    st.subheader("Growth curves")
    treatments = sorted(
        pd.concat([a["mean_df"]["treatment"] for a in analyses]).dropna().unique().tolist()
    )
    if not treatments:
        st.info("No treatments available to plot.")
    else:
        if "plot_groups" not in st.session_state:
            st.session_state.plot_groups = []
        if "plot_group_label" not in st.session_state:
            st.session_state.plot_group_label = ""
        if "plot_group_treatments" not in st.session_state:
            st.session_state.plot_group_treatments = []
        if "plot_group_use_custom_labels" not in st.session_state:
            st.session_state.plot_group_use_custom_labels = False
        if "plot_group_title" not in st.session_state:
            st.session_state.plot_group_title = ""
        if "plot_group_x_label" not in st.session_state:
            st.session_state.plot_group_x_label = ""
        if "plot_group_y_label" not in st.session_state:
            st.session_state.plot_group_y_label = ""
        st.markdown("Create one or more plot groups for overlay comparison.")
        default_x_label = f"Time ({_base_time_unit(time_unit)})"
        default_y_label = "OD"
        if not st.session_state.plot_x_label:
            st.session_state.plot_x_label = default_x_label
        if not st.session_state.plot_y_label:
            st.session_state.plot_y_label = default_y_label
        st.markdown("**Global labels**")
        st.text_input("Global plot title", key="plot_title")
        st.text_input("Global x-axis label", key="plot_x_label")
        st.text_input("Global y-axis label", key="plot_y_label")
        st.markdown("**Plot group labels**")
        st.text_input("Plot group label (optional)", key="plot_group_label")
        st.multiselect("Treatments for this group", options=treatments, key="plot_group_treatments")
        st.checkbox("Use custom labels for this plot group", key="plot_group_use_custom_labels")
        if st.session_state.plot_group_use_custom_labels:
            st.text_input("Group plot title", key="plot_group_title")
            st.text_input("Group x-axis label", key="plot_group_x_label")
            st.text_input("Group y-axis label", key="plot_group_y_label")
        def _add_plot_group():
            if st.session_state.plot_group_treatments:
                st.session_state.plot_groups.append(
                    {
                        "label": st.session_state.plot_group_label,
                        "treatments": list(st.session_state.plot_group_treatments),
                        "use_custom_labels": st.session_state.plot_group_use_custom_labels,
                        "title": st.session_state.plot_group_title,
                        "x_label": st.session_state.plot_group_x_label,
                        "y_label": st.session_state.plot_group_y_label,
                    }
                )
                st.session_state.plot_group_label = ""
                st.session_state.plot_group_treatments = []
                st.session_state.plot_group_use_custom_labels = False
                st.session_state.plot_group_title = ""
                st.session_state.plot_group_x_label = ""
                st.session_state.plot_group_y_label = ""
        st.button("Add plot group", on_click=_add_plot_group)
        if st.session_state.plot_groups:
            st.write("Plot groups")
            st.dataframe(pd.DataFrame(st.session_state.plot_groups))
            if st.button("Clear plot groups"):
                st.session_state.plot_groups = []
        plot_mode_options = ["Overlay (compare treatments)", "Small multiples", "No plots"]
        if len(analyses) > 1:
            plot_mode_options.insert(2, "Compare runs (same treatment)")
        try:
            plot_mode_index = plot_mode_options.index(st.session_state.plot_mode)
        except ValueError:
            plot_mode_index = 0
        plot_mode = st.selectbox(
            "Plot layout",
            options=plot_mode_options,
            index=plot_mode_index,
            key="plot_mode",
        )
        show_sd = st.checkbox("Show SD band", key="show_sd")
        plots_per_row = st.number_input(
            "Charts per row",
            min_value=1,
            max_value=4,
            key="plots_per_row",
        )
        custom_ticks = st.checkbox("Custom tick intervals", value=False, key="plot_custom_ticks")
        x_tick_interval = None
        y_tick_interval = None
        if custom_ticks:
            x_tick_interval = st.number_input(
                "X-axis tick interval",
                min_value=0.001,
                value=5.0,
                key="plot_x_tick_interval",
            )
            y_tick_interval = st.number_input(
                "Y-axis tick interval",
                min_value=0.001,
                value=0.1,
                key="plot_y_tick_interval",
            )
        if "compare_treatment" not in st.session_state:
            st.session_state.compare_treatment = treatments[0] if treatments else ""
        if plot_mode == "Compare runs (same treatment)":
            st.session_state.compare_treatment = st.selectbox(
                "Treatment to compare across runs",
                options=treatments,
                index=treatments.index(st.session_state.compare_treatment)
                if st.session_state.compare_treatment in treatments
                else 0,
            )
        plot_groups = st.session_state.plot_groups or [{"label": "All treatments", "treatments": treatments}]
        plot_artifacts = []
        if plot_mode != "No plots":
            for idx, group in enumerate(plot_groups, start=1):
                selected = [t for t in group["treatments"] if t in treatments]
                if not selected:
                    continue
                label = group.get("label") or f"Plot group {idx}"
                st.markdown(f"### {label}")
                use_custom = group.get("use_custom_labels", False)
                title = group.get("title") if use_custom else st.session_state.plot_title
                x_label = group.get("x_label") if use_custom else st.session_state.plot_x_label
                y_label = group.get("y_label") if use_custom else st.session_state.plot_y_label
                if not title:
                    title = st.session_state.plot_title
                if not x_label:
                    x_label = st.session_state.plot_x_label
                if not y_label:
                    y_label = st.session_state.plot_y_label
                if plot_mode == "Overlay (compare treatments)":
                    mean_df = analyses[0]["mean_df"]
                    fig = _plot_overlay(mean_df, selected, show_sd=show_sd)
                elif plot_mode == "Small multiples":
                    mean_df = analyses[0]["mean_df"]
                    fig = _plot_small_multiples(
                        mean_df,
                        selected,
                        cols_per_row=int(plots_per_row),
                        show_sd=show_sd,
                        x_label=x_label,
                        y_label=y_label,
                    )
                else:
                    treatment_choice = st.session_state.compare_treatment or selected[0]
                    fig = _plot_compare_runs(analyses, treatment_choice, show_sd=show_sd)
                _style_plot(fig, title, x_label, y_label, show_grid=False)
                _apply_tick_intervals(fig, x_tick_interval, y_tick_interval)
                st.plotly_chart(fig, width="stretch", key=f"plot_group_{idx}")
                download_fig = _prepare_download_figure(fig)
                _apply_tick_intervals(download_fig, x_tick_interval, y_tick_interval)
                html = pio.to_html(download_fig, full_html=False, include_plotlyjs="cdn")
                st.download_button(
                    "Download interactive plot (HTML)",
                    data=html,
                    file_name=f"odyssey_plot_{idx}.html",
                    mime="text/html",
                    key=f"download_plot_{idx}",
                )
                plot_artifacts.append((label, download_fig))
    st.subheader("Downloads")
    st.caption("Select what you want and download as a single zip.")
    download_results = st.checkbox("Results CSV", value=True)
    download_long_df = st.checkbox("Long format CSV", value=False)
    download_config = st.checkbox("Config JSON", value=True)
    download_report = st.checkbox("PDF report", value=True)
    download_plots = st.checkbox("Plots (HTML)", value=True)
    download_plots_png = st.checkbox("Plots (PNG)", value=False)
    plot_labels = [label for label, _ in plot_artifacts]
    selected_plots = plot_labels
    if download_plots or download_plots_png:
        with st.expander("Select specific plots", expanded=False):
            st.caption("Leave empty to include all plots.")
            selected_plots = st.multiselect(
                "Plots to include",
                options=plot_labels,
                default=[],
            )
    config_filename = st.text_input("Config filename", value="odyssey_config.json")
    if not config_filename.strip():
        config_filename = "odyssey_config.json"
    zip_filename = st.text_input("Zip filename", value="odyssey_downloads.zip")
    if not zip_filename.strip():
        zip_filename = "odyssey_downloads.zip"
    column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
    config_payload = _build_config(
        sheet_name,
        time_col,
        time_unit,
        time_window,
        fit_window_mode,
        min_points,
        blank_normalized,
        blank_cols,
        auc_mode,
        auc_window,
        auc_unit,
        notes,
        column_map,
        growth_rate_unit,
        doubling_time_unit,
        st.session_state.plot_groups,
            st.session_state.plot_mode,
            st.session_state.show_sd,
            st.session_state.plots_per_row,
            {
                "title": st.session_state.plot_title,
                "x_label": st.session_state.plot_x_label,
                "y_label": st.session_state.plot_y_label,
            },
        )
    st.caption("Your browser will ask where to save the zip.")
    if st.button("Build download zip"):
        bundle = io.BytesIO()
        with zipfile.ZipFile(bundle, "w", zipfile.ZIP_DEFLATED) as zf:
            if download_config:
                zf.writestr(config_filename, json.dumps(config_payload, indent=2))
            if download_results:
                zf.writestr("results.csv", results.to_csv(index=False))
            if download_long_df:
                if analyses:
                    zf.writestr("long_df.csv", analyses[0]["long_df"].to_csv(index=False))
            selected_set = set(selected_plots)
            if download_plots:
                for idx, (label, fig) in enumerate(plot_artifacts, start=1):
                    if selected_set and label not in selected_set:
                        continue
                    html = pio.to_html(fig, full_html=False, include_plotlyjs="cdn")
                    safe_label = _safe_filename(label)
                    zf.writestr(f"plots/plot_{idx}_{safe_label}.html", html)
            if download_plots_png:
                for idx, (label, fig) in enumerate(plot_artifacts, start=1):
                    if selected_set and label not in selected_set:
                        continue
                    safe_label = _safe_filename(label)
                    png = _plot_to_png_bytes(fig)
                    zf.writestr(f"plots/plot_{idx}_{safe_label}.png", png)
            if download_report:
                report_fig = plot_artifacts[0][1] if plot_artifacts else None
                pdf_bytes = _build_report_pdf(st.session_state.plot_title, results, report_fig, notes)
                zf.writestr("report.pdf", pdf_bytes)
        bundle.seek(0)
        st.download_button(
            "Download selected (zip)",
            data=bundle,
            file_name=zip_filename,
            mime="application/zip",
        )
    if time_unit == "hh:mm:ss":
        st.caption("Time is fit in minutes; results display uses the selected unit.")
    if st.button("Run another analysis"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
if __name__ == "__main__":
    main()
