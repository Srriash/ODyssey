import json
import os
import re
from datetime import datetime, timezone
import numpy as np
import pandas as pd
import streamlit as st
import plotly.colors as pc
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
APP_TITLE = "ODyssey Growth Curve Workbench"
CONFIG_VERSION = 1
from odyssey.analysis import (
    _base_time_unit,
    _build_column_map,
    _compute_auc,
    _convert_auc,
    _convert_duration,
    _convert_growth_rate,
    _long_format_from_map,
    _mean_sd_by_treatment_time,
    _qc_flags,
    _suggest_treatment_name,
    _validate_data,
    _window_r2_by_treatment,
    fit_growth_rates,
)
from odyssey.export import _build_config, build_download_zip
from odyssey.cache import _cached_preview_data
from odyssey.io_utils import (
    _apply_time_unit,
    _guess_time_columns,
    _parse_time_series,
    _read_excel_file,
    _read_results_zip,
    _safe_filename,
    _safe_read_json,
)
from odyssey.plotting import (
    _add_window_highlight,
    _add_window_highlight_color,
    _apply_tick_intervals,
    _plot_compare_runs,
    _plot_overlay,
    _plot_small_multiples,
    _plot_to_png_bytes,
    _prepare_download_figure,
    _style_plot,
    _to_rgba,
)
from odyssey.pipeline import analyze_file, apply_blank_normalization


def _dedupe_columns(df):
    if not df.columns.duplicated().any():
        return df
    counts = {}
    new_cols = []
    for col in df.columns:
        if col in counts:
            counts[col] += 1
            new_cols.append(f"{col}.{counts[col]}")
        else:
            counts[col] = 0
            new_cols.append(col)
    df = df.copy()
    df.columns = new_cols
    return df


def main():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.markdown(
        """
        <style>
        /* Customize Streamlit's drag-drop text inside the upload box */
        div[data-testid="stFileUploaderDropzone"] p {
          visibility: hidden;
          margin: 0;
          height: 0;
        }
        div[data-testid="stFileUploaderDropzone"] p::before {
          content: "Upload file - drag and drop files here";
          visibility: visible;
          display: block;
          height: auto;
          margin-bottom: 4px;
          font-weight: 600;
        }
        div[data-testid="stFileUploaderDropzone"] small {
          display: block;
          margin-top: 0;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        "Learn more: [ODyssey home](https://srriash.github.io/ODyssey-Growth-curve-workbench/)"
    )
    st.subheader("Compare runs")
    st.caption("Compare previously analyzed runs by uploading ODyssey zip exports.")
    st.info("Comparison does not require re-running analysis.")
    compare_upload = st.file_uploader(
        "Upload ODyssey zip(s)",
        type=["zip"],
        accept_multiple_files=True,
        help="Use the zip files generated by the Downloads section.",
    )
    if compare_upload:
        compare_runs = []
        compare_errors = []
        for uploaded in compare_upload:
            parsed, err = _read_results_zip(uploaded)
            if err:
                compare_errors.append(err)
            else:
                compare_runs.append(parsed)
        if compare_errors:
            st.warning("Some zip files could not be parsed:")
            for err in compare_errors:
                st.write(f"- {err}")
        if compare_runs:
            st.success(f"Loaded {len(compare_runs)} run(s) for comparison.")
            st.warning(
                "Comparison assumes consistent units and treatment naming across runs. "
                "If runs used different time units or window settings, interpret differences carefully."
            )
            target_time_unit = st.selectbox(
                "Convert time units to",
                options=["minutes", "hours"],
                index=0,
                key="compare_target_time_unit",
            )
            st.caption(
                "Time-based metrics and curves are converted using each run's saved time unit in its config."
            )
            rename_map = {}
            combined_frames = []
            compare_warnings = []
            time_unit_warnings = []
            required_cols = {"treatment", "replicate"}
            for run in compare_runs:
                results_df = run["results"].copy()
                rename_cols = {}
                if "treatment" not in results_df.columns and "Treatment" in results_df.columns:
                    rename_cols["Treatment"] = "treatment"
                if "replicate" not in results_df.columns and "Replicate" in results_df.columns:
                    rename_cols["Replicate"] = "replicate"
                if rename_cols:
                    results_df = results_df.rename(columns=rename_cols)
                run_config = run.get("config") or {}
                run_time_unit = run_config.get("time_unit")
                if run_time_unit:
                    run_base_unit = _base_time_unit(run_time_unit)
                else:
                    run_base_unit = target_time_unit
                    time_unit_warnings.append(
                        f"{run['name']}: missing time_unit in config; assuming {target_time_unit}"
                    )
                if run_base_unit != target_time_unit:
                    for col in results_df.columns:
                        col_lower = col.lower()
                        if "growth rate" in col_lower:
                            results_df[col] = _convert_growth_rate(
                                pd.to_numeric(results_df[col], errors="coerce"),
                                run_base_unit,
                                target_time_unit,
                            )
                        elif "doubling time" in col_lower:
                            results_df[col] = _convert_duration(
                                pd.to_numeric(results_df[col], errors="coerce"),
                                run_base_unit,
                                target_time_unit,
                            )
                        elif "window start" in col_lower or "window end" in col_lower:
                            results_df[col] = _convert_duration(
                                pd.to_numeric(results_df[col], errors="coerce"),
                                run_base_unit,
                                target_time_unit,
                            )
                        elif "auc" in col_lower:
                            results_df[col] = _convert_auc(
                                pd.to_numeric(results_df[col], errors="coerce"),
                                run_base_unit,
                                target_time_unit,
                            )
                    if any("growth rate" in c.lower() for c in results_df.columns):
                        per_label = "per hour" if target_time_unit == "hours" else "per min"
                        results_df = results_df.rename(
                            columns={
                                c: f"Growth rate ({per_label})"
                                for c in results_df.columns
                                if "growth rate" in c.lower()
                            }
                        )
                    if any("doubling time" in c.lower() for c in results_df.columns):
                        dt_label = "hours" if target_time_unit == "hours" else "min"
                        results_df = results_df.rename(
                            columns={
                                c: f"Doubling time ({dt_label})"
                                for c in results_df.columns
                                if "doubling time" in c.lower()
                            }
                        )
                    if any("auc" in c.lower() for c in results_df.columns):
                        auc_label = "OD*hour" if target_time_unit == "hours" else "OD*min"
                        results_df = results_df.rename(
                            columns={
                                c: f"AUC ({auc_label})"
                                for c in results_df.columns
                                if "auc" in c.lower()
                            }
                        )
                # Ensure unique column names to avoid concat errors after renames.
                results_df = _dedupe_columns(results_df)
                missing = required_cols - set(results_df.columns)
                if missing:
                    compare_warnings.append(
                        f"{run['name']}: missing columns {', '.join(sorted(missing))}"
                    )
                    continue
                results_df["run"] = run["name"]
                combined_frames.append(results_df)
            if compare_warnings:
                st.warning("Some runs were skipped:")
                for msg in compare_warnings:
                    st.write(f"- {msg}")
            if time_unit_warnings:
                st.warning("Some runs did not include time units:")
                for msg in time_unit_warnings:
                    st.write(f"- {msg}")
            rename_map = {}
            if combined_frames:
                combined_compare = pd.concat(combined_frames, ignore_index=True)
                combined_compare = _dedupe_columns(combined_compare)
                treatments = sorted(combined_compare["treatment"].dropna().unique().tolist())
                with st.expander("Rename treatments (optional)", expanded=False):
                    st.caption("Provide display names used in comparison tables and plots.")
                    for treatment in treatments:
                        rename_map[treatment] = st.text_input(
                            f"Rename {treatment}",
                            value=str(treatment),
                            key=f"rename_{treatment}",
                        )
                combined_compare["treatment_display"] = combined_compare["treatment"].map(rename_map)
                combined_compare = combined_compare.sort_values(["treatment_display", "run"])
                st.markdown("### Comparison table")
                st.dataframe(combined_compare)
                st.markdown("### Summary by treatment")
                numeric_compare = combined_compare.copy()
                non_numeric_cols = {"treatment", "replicate", "run", "treatment_display"}
                for col in numeric_compare.columns:
                    if col in non_numeric_cols:
                        continue
                    numeric_compare[col] = pd.to_numeric(numeric_compare[col], errors="coerce")
                numeric_cols = [
                    c
                    for c in numeric_compare.columns
                    if c not in non_numeric_cols and numeric_compare[c].notna().any()
                ]
                if numeric_cols:
                    summary = (
                        numeric_compare.groupby(["run", "treatment_display"])[numeric_cols]
                        .mean()
                        .reset_index()
                    )
                    summary = summary.sort_values(["treatment_display", "run"])
                    st.dataframe(summary)
                    metric_options = [c for c in numeric_cols if c not in ("n", "window_start", "window_end")]
                    if metric_options:
                        st.markdown("### Compare a metric across runs")
                        metric = st.selectbox("Metric", options=metric_options)
                        treatments = summary["treatment_display"].dropna().unique().tolist()
                        selected_treatments = st.multiselect(
                            "Treatments to compare",
                            options=sorted(treatments),
                            default=sorted(treatments)[:3],
                        )
                        if selected_treatments:
                            plot_df = summary[summary["treatment_display"].isin(selected_treatments)]
                            fig = go.Figure()
                            for treatment in selected_treatments:
                                subset = plot_df[plot_df["treatment_display"] == treatment]
                                fig.add_trace(
                                    go.Bar(
                                        x=subset["run"],
                                        y=subset[metric],
                                        name=str(treatment),
                                    )
                                )
                            fig.update_layout(barmode="group")
                            _style_plot(fig, f"{metric} by run", "Run", metric, show_grid=False)
                            st.plotly_chart(fig, width="stretch", key="compare_metric_plot")
                else:
                    st.info("No numeric columns available for summary.")
            curve_runs = [run for run in compare_runs if run.get("long_df") is not None]
            if curve_runs:
                st.markdown("### Compare growth curves")
                st.caption(
                    "Uses long_df.csv from each zip. Enable in Downloads when exporting. "
                    f"Curves are converted to {target_time_unit}."
                )
                show_sd_compare = st.checkbox("Show SD band", value=True, key="compare_show_sd")
                custom_ticks_compare = st.checkbox(
                    "Custom tick intervals",
                    value=False,
                    key="compare_custom_ticks",
                )
                x_tick_interval_compare = None
                y_tick_interval_compare = None
                if custom_ticks_compare:
                    x_tick_interval_compare = st.number_input(
                        "X-axis tick interval",
                        min_value=0.001,
                        value=5.0,
                        key="compare_x_tick_interval",
                    )
                    y_tick_interval_compare = st.number_input(
                        "Y-axis tick interval",
                        min_value=0.001,
                        value=0.1,
                        key="compare_y_tick_interval",
                    )
                run_labels = [run["name"] for run in curve_runs]
                selected_runs = st.multiselect(
                    "Runs to compare",
                    options=run_labels,
                    default=run_labels,
                    key="compare_runs_select",
                )
                all_treatments = sorted(
                    {
                        t
                        for run in curve_runs
                        for t in run["long_df"]["treatment"].dropna().unique().tolist()
                    }
                )
                selected_treatments = st.multiselect(
                    "Treatments to plot",
                    options=all_treatments,
                    default=all_treatments[:3],
                    key="compare_treatments_select",
                )
                if not rename_map:
                    rename_map = {treatment: treatment for treatment in all_treatments}
                if selected_runs and selected_treatments:
                    curves = []
                    for run in curve_runs:
                        if run["name"] not in selected_runs:
                            continue
                        df = run["long_df"].copy()
                        run_config = run.get("config") or {}
                        run_time_unit = run_config.get("time_unit")
                        if run_time_unit:
                            run_base_unit = _base_time_unit(run_time_unit)
                        else:
                            run_base_unit = target_time_unit
                        if run_base_unit != target_time_unit:
                            df["time"] = _convert_duration(
                                pd.to_numeric(df["time"], errors="coerce"),
                                run_base_unit,
                                target_time_unit,
                            )
                        df["run"] = run["name"]
                        curves.append(df)
                    curves_df = pd.concat(curves, ignore_index=True)
                    curves_df = curves_df[curves_df["treatment"].isin(selected_treatments)]
                    grouped = (
                        curves_df.groupby(["run", "treatment", "time"])["od"]
                        .agg(mean="mean", sd=lambda x: x.std(ddof=1))
                        .reset_index()
                        .sort_values(["treatment", "run", "time"])
                    )
                    fig = go.Figure()
                    color_cycle = pc.qualitative.Plotly
                    run_styles = {}
                    for idx, run in enumerate(selected_runs):
                        run_styles[run] = dict(dash="solid" if idx % 2 == 0 else "dot")
                    for idx, treatment in enumerate(selected_treatments):
                        color = color_cycle[idx % len(color_cycle)]
                        subset = grouped[grouped["treatment"] == treatment]
                        for run in selected_runs:
                            run_subset = subset[subset["run"] == run]
                            if run_subset.empty:
                                continue
                            line_name = f"{rename_map.get(treatment, treatment)} - {run}"
                            if show_sd_compare and not run_subset["sd"].isna().all():
                                upper = run_subset["mean"] + run_subset["sd"]
                                lower = run_subset["mean"] - run_subset["sd"]
                                fig.add_trace(
                                    go.Scatter(
                                        x=run_subset["time"],
                                        y=lower,
                                        mode="lines",
                                        line=dict(width=0),
                                        showlegend=False,
                                        hoverinfo="skip",
                                    )
                                )
                                fig.add_trace(
                                    go.Scatter(
                                        x=run_subset["time"],
                                        y=upper,
                                        mode="lines",
                                        line=dict(width=0),
                                        fill="tonexty",
                                        fillcolor=_to_rgba(color, 0.12),
                                        showlegend=False,
                                        hoverinfo="skip",
                                    )
                                )
                            fig.add_trace(
                                go.Scatter(
                                    x=run_subset["time"],
                                    y=run_subset["mean"],
                                    mode="lines",
                                    name=line_name,
                                    line=dict(color=color, **run_styles[run]),
                                )
                            )
                    _style_plot(
                        fig,
                        "Growth curves across runs",
                        f"Time ({target_time_unit})",
                        "OD",
                        show_grid=False,
                    )
                    _apply_tick_intervals(fig, x_tick_interval_compare, y_tick_interval_compare)
                    st.plotly_chart(fig, width="stretch", key="compare_growth_curves")
                    html = pio.to_html(fig, full_html=False, include_plotlyjs="cdn")
                    st.download_button(
                        "Download comparison plot (HTML)",
                        data=html,
                        file_name="odyssey_compare_growth_curves.html",
                        mime="text/html",
                        key="download_compare_growth_curves",
                    )
    st.divider()
    st.subheader("Run analysis")
    st.caption("Analyze a single Excel file and generate plots, reports, and exports.")
    excel_upload = st.file_uploader("Upload Excel file", type=["xlsx", "xls"], accept_multiple_files=False)
    if not excel_upload:
        st.info("Upload an Excel file to continue analysis.")
        return
    st.caption(
        "Optional config: upload a saved config to restore your sheet, columns, plots, and labels."
    )
    config_upload = st.file_uploader("Upload config (optional)", type=["json"])
    config = _safe_read_json(config_upload) if config_upload else None
    try:
        xls = pd.ExcelFile(excel_upload)
    except Exception as exc:
        st.error(f"Could not read Excel file: {exc}")
        return
    sheet_names = xls.sheet_names
    default_sheet = config.get("sheet_name") if config else sheet_names[0]
    if default_sheet not in sheet_names:
        default_sheet = sheet_names[0]
    sheet_name = st.selectbox("Sheet", options=sheet_names, index=sheet_names.index(default_sheet))
    try:
        df = pd.read_excel(xls, sheet_name=sheet_name, mangle_dupe_cols=False)
    except TypeError:
        df = pd.read_excel(xls, sheet_name=sheet_name)
    if df.empty:
        st.warning("The selected sheet is empty.")
        return
    time_candidates = _guess_time_columns(df)
    default_time = config.get("time_col") if config else time_candidates[0]
    if default_time not in df.columns:
        default_time = time_candidates[0]
    st.subheader("Preview")
    col1, col2 = st.columns([2, 3])
    with col1:
        time_col = st.selectbox("Time column", options=df.columns.tolist(), index=df.columns.get_loc(default_time))
        time_unit = st.selectbox("Time unit", options=["minutes", "hours", "hh:mm:ss"], index=0)
        blank_normalized_default = config.get("blank_normalized", False) if config else False
        blank_normalized = st.checkbox(
            "OD values are blank normalized",
            value=blank_normalized_default,
        )
        blank_candidates = [c for c in df.columns if c != time_col]
        blank_cols = []
        working_df = df.copy()
        if blank_candidates:
            default_blank_cols = []
            if config:
                default_blank_cols = config.get("blank_cols") or []
                if not default_blank_cols and config.get("blank_col"):
                    default_blank_cols = [config.get("blank_col")]
            default_blank_cols = [c for c in default_blank_cols if c in blank_candidates]
            blank_cols = st.multiselect(
                "Blank column(s)",
                options=blank_candidates,
                default=default_blank_cols,
            )
            if not blank_normalized and blank_cols:
                working_df = apply_blank_normalization(df, time_col, blank_cols)
            elif not blank_normalized and not blank_cols:
                st.warning("Select at least one blank column for normalization.")
        else:
            if not blank_normalized:
                st.warning("No columns available for blank normalization.")
            blank_normalized = True
        base_unit = _base_time_unit(time_unit)
        fit_window_mode = "Auto+Manual"
        min_points = int(config.get("min_points", 5)) if config else 5
        time_window = None
    preview_df = working_df.copy()
    for col in preview_df.columns:
        if preview_df[col].dtype == object:
            sample = preview_df[col].dropna().head(5)
            if any(isinstance(v, (datetime, pd.Timestamp)) for v in sample):
                preview_df[col] = preview_df[col].astype(str)
    st.dataframe(preview_df.head(10))
    validation_issues = _validate_data(
        working_df,
        time_col=time_col,
        data_cols=[c for c in working_df.columns if c != time_col],
    )
    if validation_issues:
        st.warning("Data validation warnings:")
        for issue in validation_issues[:10]:
            st.write(f"- {issue}")
    with col2:
        config_map = config.get("column_map") if config else None
        available_cols = [
            c
            for c in working_df.columns
            if c != time_col and c not in set(blank_cols)
        ]
        if "replicate_groups" not in st.session_state:
            st.session_state.replicate_groups = []
        if "plot_groups" not in st.session_state:
            st.session_state.plot_groups = []
        if "plot_mode" not in st.session_state:
            st.session_state.plot_mode = config.get("plot_mode") if config else "Overlay (compare treatments)"
        if "show_sd" not in st.session_state:
            st.session_state.show_sd = bool(config.get("show_sd")) if config else True
        if "plots_per_row" not in st.session_state:
            st.session_state.plots_per_row = (
                int(config.get("charts_per_row"))
                if config and config.get("charts_per_row")
                else 2
            )
        if "plot_title" not in st.session_state:
            st.session_state.plot_title = (
                config.get("plot_labels", {}).get("title")
                if config and config.get("plot_labels")
                else "Growth curves (mean across replicates)"
            )
        if "plot_x_label" not in st.session_state:
            st.session_state.plot_x_label = (
                config.get("plot_labels", {}).get("x_label")
                if config and config.get("plot_labels")
                else "Time"
            )
        if "plot_y_label" not in st.session_state:
            st.session_state.plot_y_label = (
                config.get("plot_labels", {}).get("y_label")
                if config and config.get("plot_labels")
                else "OD"
            )
        if "analysis_ready" not in st.session_state:
            st.session_state.analysis_ready = False
        if "analysis_payload" not in st.session_state:
            st.session_state.analysis_payload = {}
        st.markdown("Select columns that are replicates, assign a treatment name, and add the group.")
        if "rep_cols" not in st.session_state:
            st.session_state.rep_cols = []
        if "rep_name" not in st.session_state:
            st.session_state.rep_name = ""
        def _update_group_name():
            st.session_state.rep_name = _suggest_treatment_name(st.session_state.rep_cols)
        used_cols = set()
        for group in st.session_state.replicate_groups:
            used_cols.update(group.get("columns", []))
        available_group_cols = [c for c in available_cols if c not in used_cols]
        group_cols = st.multiselect(
            "Replicate columns",
            options=available_group_cols,
            key="rep_cols",
            on_change=_update_group_name,
        )
        group_name = st.text_input("Treatment name for selected replicates", key="rep_name")
        def _add_group():
            if st.session_state.rep_cols and st.session_state.rep_name:
                st.session_state.replicate_groups.append(
                    {
                        "treatment": st.session_state.rep_name,
                        "columns": list(st.session_state.rep_cols),
                    }
                )
                st.session_state.rep_cols = []
                st.session_state.rep_name = ""
        st.button("Add replicate group", on_click=_add_group)
        if st.session_state.replicate_groups:
            st.write("Replicate groups")
            st.dataframe(pd.DataFrame(st.session_state.replicate_groups))
            if st.button("Clear replicate groups"):
                st.session_state.replicate_groups = []
        if config_map and not st.session_state.replicate_groups:
            st.session_state.replicate_groups = [
                {"treatment": row.get("treatment"), "columns": [row.get("column")]}
                for row in config_map
                if row.get("column") in available_cols
            ]
        if config and config.get("plot_groups") and not st.session_state.plot_groups:
            st.session_state.plot_groups = config.get("plot_groups")
        notes = st.text_area("Notes (saved into config)", value=(config.get("notes", "") if config else ""))
    if blank_cols:
        st.subheader("Blank control")
        st.caption("Check for contamination by reviewing blank OD over time.")
        try:
            blank_time = _parse_time_series(df[time_col])
            blank_time = _apply_time_unit(
                blank_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
            )
            fig = go.Figure()
            for col in blank_cols:
                fig.add_trace(
                    go.Scatter(
                        x=blank_time,
                        y=pd.to_numeric(df[col], errors="coerce"),
                        mode="lines",
                        name=str(col),
                    )
                )
            _style_plot(fig, "Blank OD over time", st.session_state.plot_x_label, "OD", show_grid=False)
            if available_cols:
                y_vals = working_df[available_cols].apply(pd.to_numeric, errors="coerce")
                y_min = float(np.nanmin(y_vals.to_numpy())) if not y_vals.empty else None
                y_max = float(np.nanmax(y_vals.to_numpy())) if not y_vals.empty else None
                if y_min is not None and y_max is not None and np.isfinite(y_min) and np.isfinite(y_max):
                    fig.update_yaxes(range=[y_min, y_max])
            st.plotly_chart(fig, width="stretch", key="blank_control_plot")
        except Exception as exc:
            st.warning(f"Blank control preview unavailable: {exc}")
    st.subheader("Analysis settings")
    st.markdown("### Growth rate")
    default_growth_unit = (config.get("growth_rate_unit") if config else None) or (
        "1/min" if base_unit == "minutes" else "1/hour"
    )
    growth_rate_unit_options = {"min\u207B\u00B9": "1/min", "h\u207B\u00B9": "1/hour"}
    default_growth_label = "min\u207B\u00B9" if default_growth_unit == "1/min" else "h\u207B\u00B9"
    growth_rate_label = st.selectbox(
        "Growth rate unit",
        options=list(growth_rate_unit_options.keys()),
        index=0 if default_growth_label == "min\u207B\u00B9" else 1,
    )
    growth_rate_unit = growth_rate_unit_options[growth_rate_label]
    st.markdown("### Doubling time")
    default_dt_unit = (config.get("doubling_time_unit") if config else None) or (
        "min" if base_unit == "minutes" else "hour"
    )
    doubling_time_unit = st.selectbox(
        "Doubling time unit",
        options=["min", "hour"],
        index=0 if default_dt_unit == "min" else 1,
    )
    st.subheader("Preview curves")
    time_window = None
    t_min = 0.0
    t_max = 1.0
    column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
    try:
        with st.spinner("Preparing preview..."):
            column_map_json = pd.DataFrame(column_map).to_json()
            preview_mean_df, preview_long_df, t_min, t_max = _cached_preview_data(
                excel_upload.getvalue(),
                sheet_name,
                time_col,
                time_unit,
                column_map_json,
                blank_normalized,
                blank_cols,
            )
            if preview_mean_df.empty:
                st.warning("Preview unavailable: no data after parsing.")
            else:
                preview_treatments = sorted(preview_mean_df["treatment"].dropna().unique().tolist())
                signature = (sheet_name, time_col, time_unit, column_map_json)
                if st.session_state.get("preview_signature") != signature:
                    st.session_state.preview_signature = signature
                    st.session_state.preview_base_fig = _plot_overlay(
                        preview_mean_df, preview_treatments, show_sd=True
                    )
                auto_window_range = (t_min, t_max)
                try:
                    mean_by_time = (
                        preview_mean_df.groupby("time")["mean"]
                        .mean()
                        .reset_index()
                        .sort_values("time")
                    )
                    time_vals = mean_by_time["time"].to_numpy(dtype=float)
                    od_vals = mean_by_time["mean"].to_numpy(dtype=float)
                    valid = np.isfinite(time_vals) & np.isfinite(od_vals) & (od_vals > 0)
                    time_vals = time_vals[valid]
                    od_vals = od_vals[valid]
                    if len(time_vals) > 3:
                        log_od = np.log(od_vals)
                        slopes = np.diff(log_od) / np.diff(time_vals)
                        if np.isfinite(slopes).any():
                            max_slope = np.nanmax(slopes)
                            thresh = 0.8 * max_slope
                            start_idx = 0
                            for idx, val in enumerate(slopes):
                                if val >= thresh:
                                    start_idx = idx
                                    break
                            start_time = float(time_vals[start_idx])
                            span = float(t_max - t_min)
                            end_time = min(t_max, start_time + 0.2 * span)
                            auto_window_range = (start_time, end_time)
                except Exception:
                    auto_window_range = (t_min, t_max)
                st.caption("Adjust the fit window as needed.")
                time_window = st.slider(
                    "Fit window range",
                    min_value=t_min,
                    max_value=t_max,
                    value=auto_window_range,
                    key="fit_window_range",
                )
                preview_fig = go.Figure(st.session_state.preview_base_fig)
                preview_fig = _add_window_highlight(preview_fig, time_window)
                _style_plot(
                    preview_fig,
                    st.session_state.plot_title,
                    st.session_state.plot_x_label,
                    st.session_state.plot_y_label,
                    show_grid=False,
                )
                st.plotly_chart(preview_fig, width="stretch", key="preview_plot")
                st.caption(f"Highlighted window: {time_window[0]:.2f} to {time_window[1]:.2f}.")
                live_r2 = st.checkbox("Calculate R\u00B2 live (can be slow)", value=False)
                if live_r2:
                    r2_df = _window_r2_by_treatment(preview_long_df, time_window=time_window)
                    if not r2_df.empty:
                        r2_median = r2_df["r2"].median()
                        r2_mean = r2_df["r2"].mean()
                        st.caption(
                            f"Median R\u00B2 in highlighted window: {r2_median:.3f} "
                            f"(Mean: {r2_mean:.3f})"
                        )
                else:
                    if st.button("Calculate R\u00B2 for highlighted window"):
                        r2_df = _window_r2_by_treatment(preview_long_df, time_window=time_window)
                        if not r2_df.empty:
                            r2_median = r2_df["r2"].median()
                            r2_mean = r2_df["r2"].mean()
                            st.session_state.preview_r2_median = r2_median
                            st.session_state.preview_r2_mean = r2_mean
                    if "preview_r2_median" in st.session_state:
                        st.caption(
                            f"Median R\u00B2 in highlighted window: {st.session_state.preview_r2_median:.3f} "
                            f"(Mean: {st.session_state.get('preview_r2_mean', float('nan')):.3f})"
                        )
    except Exception as exc:
        st.warning(f"Preview unavailable: {exc}")
    st.markdown("### AUC")
    config_auc_unit = config.get("auc_unit") if config else None
    if config_auc_unit == "OD*min":
        config_auc_unit = "OD*min"
    if config_auc_unit == "OD*hour":
        config_auc_unit = "OD*hour"
    default_auc_unit = config_auc_unit or (
        "OD*min" if base_unit == "minutes" else "OD*hour"
    )
    auc_unit = st.selectbox(
        "AUC unit",
        options=["OD*min", "OD*hour"],
        index=0 if default_auc_unit == "OD*min" else 1,
    )
    auc_mode = st.selectbox(
        "AUC window",
        options=["Full range", "Fit window", "Custom range"],
        index=0
        if (config.get("auc_mode") if config else "Full range") == "Full range"
        else 1
        if (config.get("auc_mode") if config else "") == "Fit window"
        else 2,
    )
    auc_window = None
    auc_highlight = None
    auc_fig = None
    if "preview_base_fig" in st.session_state:
        auc_fig = go.Figure(st.session_state.preview_base_fig)
    if auc_mode == "Custom range":
        try:
            auc_time = _parse_time_series(df[time_col])
            auc_time = _apply_time_unit(
                auc_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
            )
            auc_time = auc_time.dropna()
            if not auc_time.empty:
                auc_min = float(auc_time.min())
                auc_max = float(auc_time.max())
            else:
                auc_min, auc_max = 0.0, 1.0
        except Exception:
            auc_min, auc_max = 0.0, 1.0
        default_auc = config.get("auc_window") if config else None
        auc_default = (
            tuple(default_auc) if isinstance(default_auc, list) and len(default_auc) == 2 else (auc_min, auc_max)
        )
        auc_window = st.slider(
            "AUC range",
            min_value=auc_min,
            max_value=auc_max,
            value=auc_default,
            key="auc_window",
        )
        auc_highlight = auc_window
        if auc_fig is not None:
            auc_fig = _add_window_highlight_color(auc_fig, auc_window, "rgba(239,68,68,0.25)")
    else:
        if auc_mode == "Fit window":
            auc_highlight = time_window
        else:
            auc_highlight = (t_min, t_max)
        if auc_fig is not None:
            auc_fig = _add_window_highlight_color(auc_fig, auc_highlight, "rgba(255,193,7,0.2)")
    if auc_fig is not None and auc_highlight is not None:
        _style_plot(
            auc_fig,
            "AUC window preview",
            st.session_state.plot_x_label,
            st.session_state.plot_y_label,
            show_grid=False,
        )
        st.plotly_chart(auc_fig, width="stretch", key="auc_preview_plot")
    col_a, _ = st.columns([1, 1])
    with col_a:
        run_button = st.button("Run analysis", type="primary")
    if run_button:
        if not available_cols:
            st.error("No treatment columns selected.")
            return
        column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
        base_unit = _base_time_unit(time_unit)
        target_mu_unit = "minutes" if growth_rate_unit == "1/min" else "hours"
        target_dt_unit = "minutes" if doubling_time_unit == "min" else "hours"
        with st.spinner("Running analysis..."):
            analyses = []
            errors = []
            uploaded = excel_upload
            try:
                if auc_mode == "Full range":
                    auc_use_window = None
                elif auc_mode == "Fit window":
                    auc_use_window = time_window
                else:
                    auc_use_window = auc_window
                if auc_use_window is None:
                    auc_time = _parse_time_series(df[time_col])
                    auc_time = _apply_time_unit(
                        auc_time, time_unit if time_unit != "hh:mm:ss" else "minutes"
                    )
                    auc_time = auc_time.dropna()
                    if not auc_time.empty:
                        auc_window_range = (float(auc_time.min()), float(auc_time.max()))
                    else:
                        auc_window_range = (np.nan, np.nan)
                else:
                    auc_window_range = (float(auc_use_window[0]), float(auc_use_window[1]))
                analysis = analyze_file(
                    uploaded,
                    sheet_name,
                    time_col,
                    time_unit,
                    column_map,
                    time_window,
                    False,
                    min_points,
                    blank_normalized,
                    blank_cols,
                    auc_window=auc_use_window,
                )
                analysis["results"]["run"] = uploaded.name
                analyses.append(analysis)
            except Exception as exc:
                errors.append(str(exc))
            if errors:
                st.error("Some files could not be processed:")
                for err in errors:
                    st.write(f"- {err}")
                if not analyses:
                    return
            combined_results = pd.concat([a["results"] for a in analyses], ignore_index=True)
            combined_auc = pd.concat([a["auc"] for a in analyses], ignore_index=True)
            combined_results = combined_results.merge(
                combined_auc, on=["treatment", "replicate"], how="left"
            )
            results_display = combined_results.copy()
            results_display["mu"] = _convert_growth_rate(results_display["mu"], base_unit, target_mu_unit)
            results_display["doubling_time"] = _convert_duration(
                results_display["doubling_time"], base_unit, target_dt_unit
            )
            target_auc_unit = "minutes" if auc_unit == "OD*min" else "hours"
            results_display["auc"] = _convert_auc(results_display["auc"], base_unit, target_auc_unit)
            mu_label = f"Growth rate ({growth_rate_label})"
            dt_label = f"Doubling time ({doubling_time_unit})"
            auc_label = f"AUC ({auc_unit})"
            results_display = results_display.rename(
                columns={"mu": mu_label, "doubling_time": dt_label, "auc": auc_label}
            )
            results_display["AUC window start"] = auc_window_range[0]
            results_display["AUC window end"] = auc_window_range[1]
            results_display = _qc_flags(results_display, r2_threshold=0.9)
            if "run" in results_display.columns:
                results_display = results_display.drop(columns=["run"])
            results_display = results_display.rename(
                columns={
                    "treatment": "Treatment",
                    "replicate": "Replicate",
                    "n": "N",
                    "intercept": "Intercept",
                    "r2": "R\u00B2",
                    "window_start": "Exponential window start",
                    "window_end": "Exponential window end",
                    "qc_flags": "QC flags",
                }
            )
            st.session_state.analysis_ready = True
            st.session_state.analysis_payload = {
                "analyses": analyses,
                "results": results_display,
            }
    if not st.session_state.analysis_ready:
        st.info("Run analysis to generate results and plots.")
        return
    analyses = st.session_state.analysis_payload["analyses"]
    results = st.session_state.analysis_payload["results"]
    st.subheader("Fit results")
    st.dataframe(results)
    st.markdown(
        "Fit definitions: "
        "**N** = number of points in the fit window; "
        "**Growth rate** = growth rate from the selected fit window (slope of ln(OD) vs time); "
        "**R<sup>2</sup>** = coefficient of determination for the linear fit; "
        "**Doubling time** = time for OD to double; "
        "**AUC** = area under the curve; "
        "**Exponential window start/end** = time range used for the fit; "
        "**QC flags** = low R<sup>2</sup> or non-positive growth rate.",
        unsafe_allow_html=True,
    )
    st.subheader("Growth curves")
    treatments = sorted(
        pd.concat([a["mean_df"]["treatment"] for a in analyses]).dropna().unique().tolist()
    )
    if not treatments:
        st.info("No treatments available to plot.")
    else:
        if "plot_groups" not in st.session_state:
            st.session_state.plot_groups = []
        if "plot_group_label" not in st.session_state:
            st.session_state.plot_group_label = ""
        if "plot_group_treatments" not in st.session_state:
            st.session_state.plot_group_treatments = []
        if "plot_group_use_custom_labels" not in st.session_state:
            st.session_state.plot_group_use_custom_labels = False
        if "plot_group_title" not in st.session_state:
            st.session_state.plot_group_title = ""
        if "plot_group_x_label" not in st.session_state:
            st.session_state.plot_group_x_label = ""
        if "plot_group_y_label" not in st.session_state:
            st.session_state.plot_group_y_label = ""
        st.markdown("Create one or more plot groups for overlay comparison.")
        default_x_label = f"Time ({_base_time_unit(time_unit)})"
        default_y_label = "OD"
        if not st.session_state.plot_x_label:
            st.session_state.plot_x_label = default_x_label
        if not st.session_state.plot_y_label:
            st.session_state.plot_y_label = default_y_label
        st.markdown("**Global labels**")
        st.text_input("Global plot title", key="plot_title")
        st.text_input("Global x-axis label", key="plot_x_label")
        st.text_input("Global y-axis label", key="plot_y_label")
        st.markdown("**Plot group labels**")
        st.text_input("Plot group label (optional)", key="plot_group_label")
        st.multiselect("Treatments for this group", options=treatments, key="plot_group_treatments")
        st.checkbox("Use custom labels for this plot group", key="plot_group_use_custom_labels")
        if st.session_state.plot_group_use_custom_labels:
            st.text_input("Group plot title", key="plot_group_title")
            st.text_input("Group x-axis label", key="plot_group_x_label")
            st.text_input("Group y-axis label", key="plot_group_y_label")
        def _add_plot_group():
            if st.session_state.plot_group_treatments:
                st.session_state.plot_groups.append(
                    {
                        "label": st.session_state.plot_group_label,
                        "treatments": list(st.session_state.plot_group_treatments),
                        "use_custom_labels": st.session_state.plot_group_use_custom_labels,
                        "title": st.session_state.plot_group_title,
                        "x_label": st.session_state.plot_group_x_label,
                        "y_label": st.session_state.plot_group_y_label,
                    }
                )
                st.session_state.plot_group_label = ""
                st.session_state.plot_group_treatments = []
                st.session_state.plot_group_use_custom_labels = False
                st.session_state.plot_group_title = ""
                st.session_state.plot_group_x_label = ""
                st.session_state.plot_group_y_label = ""
        st.button("Add plot group", on_click=_add_plot_group)
        if st.session_state.plot_groups:
            st.write("Plot groups")
            st.dataframe(pd.DataFrame(st.session_state.plot_groups))
            if st.button("Clear plot groups"):
                st.session_state.plot_groups = []
        plot_mode_options = ["Overlay (compare treatments)", "Small multiples", "No plots"]
        if len(analyses) > 1:
            plot_mode_options.insert(2, "Compare runs (same treatment)")
        try:
            plot_mode_index = plot_mode_options.index(st.session_state.plot_mode)
        except ValueError:
            plot_mode_index = 0
        plot_mode = st.selectbox(
            "Plot layout",
            options=plot_mode_options,
            index=plot_mode_index,
            key="plot_mode",
        )
        show_sd = st.checkbox("Show SD band", key="show_sd")
        plots_per_row = st.number_input(
            "Charts per row",
            min_value=1,
            max_value=4,
            key="plots_per_row",
        )
        custom_ticks = st.checkbox("Custom tick intervals", value=False, key="plot_custom_ticks")
        x_tick_interval = None
        y_tick_interval = None
        if custom_ticks:
            x_tick_interval = st.number_input(
                "X-axis tick interval",
                min_value=0.001,
                value=5.0,
                key="plot_x_tick_interval",
            )
            y_tick_interval = st.number_input(
                "Y-axis tick interval",
                min_value=0.001,
                value=0.1,
                key="plot_y_tick_interval",
            )
        if "compare_treatment" not in st.session_state:
            st.session_state.compare_treatment = treatments[0] if treatments else ""
        if plot_mode == "Compare runs (same treatment)":
            st.session_state.compare_treatment = st.selectbox(
                "Treatment to compare across runs",
                options=treatments,
                index=treatments.index(st.session_state.compare_treatment)
                if st.session_state.compare_treatment in treatments
                else 0,
            )
        plot_groups = st.session_state.plot_groups or [{"label": "All treatments", "treatments": treatments}]
        plot_artifacts = []
        if plot_mode != "No plots":
            for idx, group in enumerate(plot_groups, start=1):
                selected = [t for t in group["treatments"] if t in treatments]
                if not selected:
                    continue
                label = group.get("label") or f"Plot group {idx}"
                st.markdown(f"### {label}")
                use_custom = group.get("use_custom_labels", False)
                title = group.get("title") if use_custom else st.session_state.plot_title
                x_label = group.get("x_label") if use_custom else st.session_state.plot_x_label
                y_label = group.get("y_label") if use_custom else st.session_state.plot_y_label
                if not title:
                    title = st.session_state.plot_title
                if not x_label:
                    x_label = st.session_state.plot_x_label
                if not y_label:
                    y_label = st.session_state.plot_y_label
                if plot_mode == "Overlay (compare treatments)":
                    mean_df = analyses[0]["mean_df"]
                    fig = _plot_overlay(mean_df, selected, show_sd=show_sd)
                elif plot_mode == "Small multiples":
                    mean_df = analyses[0]["mean_df"]
                    fig = _plot_small_multiples(
                        mean_df,
                        selected,
                        cols_per_row=int(plots_per_row),
                        show_sd=show_sd,
                        x_label=x_label,
                        y_label=y_label,
                    )
                else:
                    treatment_choice = st.session_state.compare_treatment or selected[0]
                    fig = _plot_compare_runs(analyses, treatment_choice, show_sd=show_sd)
                _style_plot(fig, title, x_label, y_label, show_grid=False)
                _apply_tick_intervals(fig, x_tick_interval, y_tick_interval)
                st.plotly_chart(fig, width="stretch", key=f"plot_group_{idx}")
                download_fig = _prepare_download_figure(fig)
                _apply_tick_intervals(download_fig, x_tick_interval, y_tick_interval)
                html = pio.to_html(download_fig, full_html=False, include_plotlyjs="cdn")
                st.download_button(
                    "Download interactive plot (HTML)",
                    data=html,
                    file_name=f"odyssey_plot_{idx}.html",
                    mime="text/html",
                    key=f"download_plot_{idx}",
                )
                plot_artifacts.append((label, download_fig))
    st.subheader("Downloads")
    st.caption("Select what you want and download as a single zip.")
    if "download_ready" not in st.session_state:
        st.session_state.download_ready = False
    download_results = st.checkbox("Results CSV", value=True)
    download_long_df = st.checkbox("Long format CSV", value=False)
    download_config = st.checkbox("Config JSON", value=True)
    download_plots = st.checkbox("Plots (HTML)", value=True)
    st.caption(
        "Note: ZIP exports include only HTML plots. PNGs must be downloaded individually from each plot above. "
        "For comparing runs, the Long format CSV is needed; PNG/PDF are not required."
    )
    plot_labels = [label for label, _ in plot_artifacts]
    selected_plots = plot_labels
    if download_plots:
        with st.expander("Select specific plots", expanded=False):
            st.caption("Leave empty to include all plots.")
            selected_plots = st.multiselect(
                "Plots to include",
                options=plot_labels,
                default=[],
            )
    config_filename = "odyssey_config.json"
    zip_filename = "odyssey_downloads.zip"
    column_map = _build_column_map(available_cols, st.session_state.replicate_groups)
    config_payload = _build_config(
        sheet_name,
        time_col,
        time_unit,
        time_window,
        fit_window_mode,
        min_points,
        blank_normalized,
        blank_cols,
        auc_mode,
        auc_window,
        auc_unit,
        notes,
        column_map,
        growth_rate_unit,
        doubling_time_unit,
        st.session_state.plot_groups,
            st.session_state.plot_mode,
            st.session_state.show_sd,
            st.session_state.plots_per_row,
            {
                "title": st.session_state.plot_title,
                "x_label": st.session_state.plot_x_label,
                "y_label": st.session_state.plot_y_label,
            },
        )
    st.caption("Build the zip, then click download.")
    if "download_zip_bytes" not in st.session_state:
        st.session_state.download_zip_bytes = None
    if "download_zip_name" not in st.session_state:
        st.session_state.download_zip_name = None
    if "download_zip_error" not in st.session_state:
        st.session_state.download_zip_error = None

    progress_log = st.empty()
    progress_bar = st.progress(0)
    progress_stage = st.empty()
    build_clicked = st.button("Build download zip", key="build_zip")
    if build_clicked:
        with st.spinner("Building zip..."):
            try:
                build_start = datetime.now()
                prev_timings = st.session_state.get("download_zip_timings") or {}
                st.session_state.download_zip_prev_total = prev_timings.get("total_s")

                def _progress_cb(stage, done, total):
                    progress_bar.progress(min(done / total, 1.0))
                    elapsed = (datetime.now() - build_start).total_seconds()
                    progress_stage.caption(
                        f"Building: {stage} ({done}/{total}) • {elapsed:.1f}s"
                    )
                    progress_log.text("Building zip...")

                zip_bytes, zip_name, build_warnings, build_timings = build_download_zip(
                    results=results,
                    analyses=analyses,
                    plot_artifacts=plot_artifacts,
                    config_payload=config_payload,
                    config_filename=config_filename,
                    download_results=download_results,
                    download_long_df=download_long_df,
                    download_config=download_config,
                    download_plots=download_plots,
                    selected_plots=selected_plots,
                    zip_filename=zip_filename,
                    progress_cb=_progress_cb,
                )
                st.session_state.download_zip_bytes = zip_bytes
                st.session_state.download_zip_name = zip_name
                st.session_state.download_zip_timings = build_timings
                st.session_state.download_zip_error = None
                for msg in build_warnings:
                    st.warning(msg)
            except Exception as exc:
                st.session_state.download_zip_error = str(exc)
        st.rerun()

    if st.session_state.get("download_zip_error"):
        st.error(f"Zip build failed: {st.session_state.download_zip_error}")
    if st.session_state.get("download_zip_bytes"):
        st.success("Zip ready for download.")
        st.download_button(
            "Download selected (zip)",
            data=st.session_state.download_zip_bytes,
            file_name=st.session_state.get("download_zip_name", "odyssey_downloads.zip"),
            mime="application/zip",
        )
        st.caption(f"Zip size: {len(st.session_state.download_zip_bytes)} bytes")
        timings = st.session_state.get("download_zip_timings")
        if timings:
            ordered = [
                "config_json_s",
                "results_csv_s",
                "long_df_csv_s",
                "plots_html_s",
                "total_s",
            ]
            progress_lines = []
            total = timings.get("total_s") or max(timings.values())
            for key in ordered:
                if key not in timings:
                    continue
                progress_lines.append(f"{key}: {timings[key]:.2f}s")
            st.caption("Build timings (s): " + ", ".join(progress_lines))
    else:
        st.info("Build a zip to enable the download button.")
    if time_unit == "hh:mm:ss":
        st.caption("Time is fit in minutes; results display uses the selected unit.")
if __name__ == "__main__":
    main()
